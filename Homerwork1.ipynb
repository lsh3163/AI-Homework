{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homerwork1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNGT59qjJTac5rMWUIK8nn7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsh3163/AI-Homework/blob/main/Homerwork1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1JIsdME55p7"
      },
      "source": [
        "# 인공지능 과제1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb1Wc0nP6Gy_"
      },
      "source": [
        "## Gathering some data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR1beMBT51vO"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "torch.set_printoptions(edgeitems=2, linewidth=75)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5KiJFKt6fwH"
      },
      "source": [
        "*  the` t_c `values are temperatures in Celsius\n",
        "*  the `t_v `values are our unknown units\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urZa4k1C6MKY"
      },
      "source": [
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUtljkt66w6k"
      },
      "source": [
        "## Choosing a linear model as a first try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XrwjZqr6uyO"
      },
      "source": [
        "def model(t_u, w, b):\n",
        "  return w*t_u+b\n",
        "\n",
        "## Mean Squared Error  \n",
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p-t_c)**2\n",
        "  return squared_diffs.mean()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqqeY66D6_Z8",
        "outputId": "c2425463-5b61-40d6-9889-c05aa8a4964e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "w = torch.ones(())\n",
        "b = torch.zeros(())\n",
        "t_p = model(t_u, w, b)\n",
        "t_p"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([35.7000, 55.9000, 58.2000, 81.9000, 56.3000, 48.9000, 33.9000,\n",
              "        21.8000, 48.4000, 60.4000, 68.4000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEHYWJT47MWv",
        "outputId": "58c2e6fb-45b2-4207-d19e-f11bf773b4ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "loss = loss_fn(t_p, t_c)\n",
        "loss"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1763.8848)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCL3PokI72m7"
      },
      "source": [
        "## Decreasing loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DulAcus07x1_"
      },
      "source": [
        "delta = 0.1\n",
        "loss_rate_of_change_w = (loss_fn(model(t_u, w+delta, b), t_c) - loss_fn(model(t_u, w-delta, b), t_c)) / (2.0*delta)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feb_9U-B9uZo"
      },
      "source": [
        "learning_rate = 1e-2\n",
        "w = w - learning_rate * loss_rate_of_change_w"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEjYs6o892PN"
      },
      "source": [
        "loss_rate_of_change_b = (loss_fn(model(t_u, w, b+delta), t_c) - loss_fn(model(t_u, w, b-delta), t_c)) / (2.0*delta)\n",
        "b = b - learning_rate * loss_rate_of_change_b"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoEFW5Fa-EUg"
      },
      "source": [
        "## Applying the derivatives to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm5rgBD79_a-"
      },
      "source": [
        "def dloss_fn(t_p, t_c):\n",
        "  dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)\n",
        "  return dsq_diffs\n",
        "\n",
        "def dmodel_dw(t_u, w, b):\n",
        "  return t_u\n",
        "\n",
        "def dmodel_db(t_u, w, b):\n",
        "  return 1.0\n",
        "\n",
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p - t_c)**2\n",
        "  return squared_diffs.mean()\n",
        "\n",
        "def model(t_u, w, b):\n",
        "  return w*t_u+b"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg95RzK7-ssU"
      },
      "source": [
        "## Defining the Gradient Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M1kfJsL-m4Y"
      },
      "source": [
        "def grad_fn(t_u, t_c, t_p, w, b):\n",
        "  dloss_dtp = dloss_fn(t_p, t_c)\n",
        "  dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b)\n",
        "  dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n",
        "  return torch.stack([dloss_dw.sum(), dloss_db.sum()])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqPVpPW4_BXv"
      },
      "source": [
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c, print_params=True):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    w, b = params\n",
        "\n",
        "    t_p = model(t_u, w, b)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "    grad = grad_fn(t_u, t_c, t_p, w, b)\n",
        "\n",
        "    params = params - learning_rate * grad\n",
        "    if epoch in (1, 2, 3, 10, 11, 99, 100, 4000, 5000):\n",
        "      print(\"Epoch %d, Loss %f\" % (epoch, float(loss)))\n",
        "      if print_params:\n",
        "        print(' Params:', params)\n",
        "        print(' Grad:', grad)\n",
        "      if epoch in (4, 12, 101):\n",
        "        print('...')\n",
        "      if not torch.isfinite(loss).all():\n",
        "        break\n",
        "  return params"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnlaHx1-AB6Q",
        "outputId": "7a9c6760-0e2a-4fd8-913a-64ae91c52c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_loop(\n",
        "    n_epochs=100,\n",
        "    learning_rate=1e-2,\n",
        "    params=torch.tensor([1.0, 0.0]),\n",
        "    t_u=t_u,\n",
        "    t_c=t_c\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss 1763.884766\n",
            " Params: tensor([-44.1730,  -0.8260])\n",
            " Grad: tensor([4517.2964,   82.6000])\n",
            "Epoch 2, Loss 5802484.500000\n",
            " Params: tensor([2568.4011,   45.1637])\n",
            " Grad: tensor([-261257.4062,   -4598.9702])\n",
            "Epoch 3, Loss 19408029696.000000\n",
            " Params: tensor([-148527.7344,   -2616.3931])\n",
            " Grad: tensor([15109614.0000,   266155.6875])\n",
            "Epoch 10, Loss 90901105189019073810297959556841472.000000\n",
            " Params: tensor([3.2144e+17, 5.6621e+15])\n",
            " Grad: tensor([-3.2700e+19, -5.7600e+17])\n",
            "Epoch 11, Loss inf\n",
            " Params: tensor([-1.8590e+19, -3.2746e+17])\n",
            " Grad: tensor([1.8912e+21, 3.3313e+19])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.8590e+19, -3.2746e+17])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u9xboVWAgo6"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFAYuNOoANRw",
        "outputId": "d631aa45-8dfb-4ada-9f2f-5285128233bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_loop(\n",
        "    n_epochs=100,\n",
        "    learning_rate=1e-4,\n",
        "    params=torch.tensor([1.0, 0.0]),\n",
        "    t_u=t_u,\n",
        "    t_c=t_c\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss 1763.884766\n",
            " Params: tensor([ 0.5483, -0.0083])\n",
            " Grad: tensor([4517.2964,   82.6000])\n",
            "Epoch 2, Loss 323.090515\n",
            " Params: tensor([ 0.3623, -0.0118])\n",
            " Grad: tensor([1859.5493,   35.7843])\n",
            "Epoch 3, Loss 78.929634\n",
            " Params: tensor([ 0.2858, -0.0135])\n",
            " Grad: tensor([765.4666,  16.5122])\n",
            "Epoch 10, Loss 29.105247\n",
            " Params: tensor([ 0.2324, -0.0166])\n",
            " Grad: tensor([1.4803, 3.0544])\n",
            "Epoch 11, Loss 29.104168\n",
            " Params: tensor([ 0.2323, -0.0169])\n",
            " Grad: tensor([0.5781, 3.0384])\n",
            "Epoch 99, Loss 29.023582\n",
            " Params: tensor([ 0.2327, -0.0435])\n",
            " Grad: tensor([-0.0533,  3.0226])\n",
            "Epoch 100, Loss 29.022667\n",
            " Params: tensor([ 0.2327, -0.0438])\n",
            " Grad: tensor([-0.0532,  3.0226])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2327, -0.0438])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEntaBTLAnDE"
      },
      "source": [
        "## Normalizing inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPN1RKyHAkDz",
        "outputId": "c46ffe8c-6ad5-4e38-89bf-ea6ad8ee7ebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t_un = 0.1 * t_u\n",
        "\n",
        "params = training_loop(\n",
        "    n_epochs=100,\n",
        "    learning_rate=1e-2,\n",
        "    params=torch.tensor([1.0, 0.0]),\n",
        "    t_u=t_un,\n",
        "    t_c=t_c\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss 80.364342\n",
            " Params: tensor([1.7761, 0.1064])\n",
            " Grad: tensor([-77.6140, -10.6400])\n",
            "Epoch 2, Loss 37.574913\n",
            " Params: tensor([2.0848, 0.1303])\n",
            " Grad: tensor([-30.8623,  -2.3864])\n",
            "Epoch 3, Loss 30.871077\n",
            " Params: tensor([2.2094, 0.1217])\n",
            " Grad: tensor([-12.4631,   0.8587])\n",
            "Epoch 10, Loss 29.030489\n",
            " Params: tensor([ 2.3232, -0.0710])\n",
            " Grad: tensor([-0.5355,  2.9295])\n",
            "Epoch 11, Loss 28.941877\n",
            " Params: tensor([ 2.3284, -0.1003])\n",
            " Grad: tensor([-0.5240,  2.9264])\n",
            "Epoch 99, Loss 22.214186\n",
            " Params: tensor([ 2.7508, -2.4910])\n",
            " Grad: tensor([-0.4453,  2.5208])\n",
            "Epoch 100, Loss 22.148710\n",
            " Params: tensor([ 2.7553, -2.5162])\n",
            " Grad: tensor([-0.4446,  2.5165])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJLVSnL_AuIm",
        "outputId": "03831854-5566-4a60-ce2a-db0fd4ca1520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t_un = 0.1 * t_u\n",
        "\n",
        "training_loop(\n",
        "    n_epochs=5000,\n",
        "    learning_rate=1e-2,\n",
        "    params=torch.tensor([1.0, 0.0]),\n",
        "    t_u=t_un,\n",
        "    t_c=t_c\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss 80.364342\n",
            " Params: tensor([1.7761, 0.1064])\n",
            " Grad: tensor([-77.6140, -10.6400])\n",
            "Epoch 2, Loss 37.574913\n",
            " Params: tensor([2.0848, 0.1303])\n",
            " Grad: tensor([-30.8623,  -2.3864])\n",
            "Epoch 3, Loss 30.871077\n",
            " Params: tensor([2.2094, 0.1217])\n",
            " Grad: tensor([-12.4631,   0.8587])\n",
            "Epoch 10, Loss 29.030489\n",
            " Params: tensor([ 2.3232, -0.0710])\n",
            " Grad: tensor([-0.5355,  2.9295])\n",
            "Epoch 11, Loss 28.941877\n",
            " Params: tensor([ 2.3284, -0.1003])\n",
            " Grad: tensor([-0.5240,  2.9264])\n",
            "Epoch 99, Loss 22.214186\n",
            " Params: tensor([ 2.7508, -2.4910])\n",
            " Grad: tensor([-0.4453,  2.5208])\n",
            "Epoch 100, Loss 22.148710\n",
            " Params: tensor([ 2.7553, -2.5162])\n",
            " Grad: tensor([-0.4446,  2.5165])\n",
            "Epoch 4000, Loss 2.927680\n",
            " Params: tensor([  5.3643, -17.2853])\n",
            " Grad: tensor([-0.0006,  0.0033])\n",
            "Epoch 5000, Loss 2.927648\n",
            " Params: tensor([  5.3671, -17.3012])\n",
            " Grad: tensor([-0.0001,  0.0006])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klDnp-DMBEF1"
      },
      "source": [
        "The exact vlaues would be w=5.3671 and b=-17.3012"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn4TuE8rA0xF",
        "outputId": "c4eb81b3-0eba-455d-dd41-3c24b5776b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "t_p = model(t_un, *params)\n",
        "\n",
        "fig = plt.figure(dpi=100)\n",
        "plt.xlabel(\"Temperature (F)\")\n",
        "plt.ylabel(\"Temperature (C)\")\n",
        "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
        "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fdbe6407710>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDwfVgqZBx4C"
      },
      "source": [
        "## Autograd : Backpropagating all things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdi7kaAKBgol",
        "outputId": "679a0748-533c-46e4-f054-33730dc59235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = torch.tensor([1.0,0.0], requires_grad=True)\n",
        "params"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0.], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1L6ZyvzB8cn",
        "outputId": "d2333d3d-0539-4d7b-f665-5f610a6c2704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if params.grad is not None:\n",
        "  params.grad.zero_()\n",
        "\n",
        "loss = loss_fn(model(t_u, *params), t_c)\n",
        "loss.backward()\n",
        "params.grad"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4517.2969,   82.6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDcEd8nAIbyL"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h-ExMNWCXRx"
      },
      "source": [
        "def training_loop(n_epochs, learning_rate, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    if params.grad is not None:\n",
        "      params.grad.zero_()\n",
        "\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "    loss.backward()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      params -= learning_rate * params.grad\n",
        "    if epoch % 500 == 0:\n",
        "      print(\"Epoch %d, Loss %f\" % (epoch, float(loss)))\n",
        "  return params"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkCaPL_IH3q-",
        "outputId": "d2551690-a48c-4f81-9d7e-2feb4fd0ce65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    learning_rate = 1e-2,\n",
        "    params = torch.tensor([1.0, 0.0], requires_grad=True),\n",
        "    t_u = t_un,\n",
        "    t_c = t_c\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.860115\n",
            "Epoch 1000, Loss 3.828538\n",
            "Epoch 1500, Loss 3.092191\n",
            "Epoch 2000, Loss 2.957698\n",
            "Epoch 2500, Loss 2.933134\n",
            "Epoch 3000, Loss 2.928648\n",
            "Epoch 3500, Loss 2.927830\n",
            "Epoch 4000, Loss 2.927679\n",
            "Epoch 4500, Loss 2.927652\n",
            "Epoch 5000, Loss 2.927647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnRR96IBIV9l",
        "outputId": "3b3b24b0-2ac6-4c88-b8f0-bea01da1f696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch.optim as optim\n",
        "dir(optim)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ASGD',\n",
              " 'Adadelta',\n",
              " 'Adagrad',\n",
              " 'Adam',\n",
              " 'AdamW',\n",
              " 'Adamax',\n",
              " 'LBFGS',\n",
              " 'Optimizer',\n",
              " 'RMSprop',\n",
              " 'Rprop',\n",
              " 'SGD',\n",
              " 'SparseAdam',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_multi_tensor',\n",
              " 'functional',\n",
              " 'lr_scheduler',\n",
              " 'swa_utils']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oa_IJ5DIagb"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    \n",
        "\n",
        "    t_p = model(t_u, *params)\n",
        "    loss = loss_fn(t_p, t_c)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 500 == 0:\n",
        "      print(\"Epoch %d, Loss %f\" % (epoch, float(loss)))\n",
        "  return params"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtFQZ5I9I3Lj",
        "outputId": "b7942408-089f-4f64-e224-5dde12314832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = torch.tensor([1.0,0.0], requires_grad=True)\n",
        "learning_rate=1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer=optimizer,\n",
        "    params = params,\n",
        "    t_u = t_un,\n",
        "    t_c = t_c\n",
        ")\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.860120\n",
            "Epoch 1000, Loss 3.828538\n",
            "Epoch 1500, Loss 3.092191\n",
            "Epoch 2000, Loss 2.957698\n",
            "Epoch 2500, Loss 2.933134\n",
            "Epoch 3000, Loss 2.928648\n",
            "Epoch 3500, Loss 2.927830\n",
            "Epoch 4000, Loss 2.927679\n",
            "Epoch 4500, Loss 2.927652\n",
            "Epoch 5000, Loss 2.927647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.3671, -17.3012], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heHEhVHwJF3G",
        "outputId": "39da1b67-c3a7-4ff2-dc83-8ac6c401f5ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = torch.tensor([1.0,0.0], requires_grad=True)\n",
        "learning_rate=1e-1\n",
        "optimizer = optim.Adam([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 5000,\n",
        "    optimizer=optimizer,\n",
        "    params = params,\n",
        "    t_u = t_u,\n",
        "    t_c = t_c\n",
        ")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 500, Loss 7.612900\n",
            "Epoch 1000, Loss 3.086700\n",
            "Epoch 1500, Loss 2.928579\n",
            "Epoch 2000, Loss 2.927644\n",
            "Epoch 2500, Loss 2.927645\n",
            "Epoch 3000, Loss 2.927646\n",
            "Epoch 3500, Loss 2.927645\n",
            "Epoch 4000, Loss 2.927646\n",
            "Epoch 4500, Loss 2.927646\n",
            "Epoch 5000, Loss 2.927645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0.5368, -17.3048], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDKPSdE2M-Gw"
      },
      "source": [
        "## Spliting a Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UineOZX0JU37",
        "outputId": "c3da7630-b755-4d8e-b15f-1b2d641eb00a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_indices, val_indices"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 4,  0, 10,  1,  6,  8,  7,  9,  2]), tensor([3, 5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAYTGl4mNn-c"
      },
      "source": [
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]\n",
        "\n",
        "train_t_un = 0.1 * train_t_u\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG4VO92uN6z5"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    \n",
        "    if params.grad is not None:\n",
        "      params.grad.zero_()  \n",
        "    with torch.set_grad_enabled(True):\n",
        "      train_t_p = model(train_t_u, *params)\n",
        "      train_loss = loss_fn(train_t_p, train_t_c)\n",
        "    with torch.no_grad():\n",
        "      val_t_p = model(val_t_u, *params)\n",
        "      val_loss = loss_fn(val_t_p, val_t_c)\n",
        "      assert val_loss.requires_grad==False\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch<=3 or epoch % 500 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f}, \"f\"Validation loss{val_loss.item():.4f}\")\n",
        "  return params"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rDVNWouOq1N",
        "outputId": "60d64eb6-e809-41be-a8f2-b824e9b8cdeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs=3000,\n",
        "    optimizer=optimizer,\n",
        "    params=params,\n",
        "    train_t_u=train_t_un,\n",
        "    val_t_u=val_t_un,\n",
        "    train_t_c=train_t_c,\n",
        "    val_t_c=val_t_c\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss 53.5444, Validation loss201.0541\n",
            "Epoch 2, Training loss 30.5667, Validation loss115.4398\n",
            "Epoch 3, Training loss 25.5510, Validation loss85.4571\n",
            "Epoch 500, Training loss 7.7695, Validation loss21.5329\n",
            "Epoch 1000, Training loss 4.1600, Validation loss9.2849\n",
            "Epoch 1500, Training loss 3.3756, Validation loss5.3324\n",
            "Epoch 2000, Training loss 3.2051, Validation loss3.8717\n",
            "Epoch 2500, Training loss 3.1681, Validation loss3.2738\n",
            "Epoch 3000, Training loss 3.1600, Validation loss3.0131\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  5.0943, -16.0027], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGss1i6xSCmO"
      },
      "source": [
        "## Homework \n",
        "\n",
        "### Gathering Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMnzQnGbPRrC"
      },
      "source": [
        "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
        "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
        "t_c = torch.tensor(t_c)\n",
        "t_u = torch.tensor(t_u)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5H-fyzJSl7H",
        "outputId": "baa6b24e-f2e2-40a1-9c1b-1d61a994de36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_samples = t_u.shape[0]\n",
        "n_val = int(0.2 * n_samples)\n",
        "\n",
        "shuffled_indices = torch.randperm(n_samples)\n",
        "\n",
        "train_indices = shuffled_indices[:-n_val]\n",
        "val_indices = shuffled_indices[-n_val:]\n",
        "\n",
        "train_indices, val_indices"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 2,  8, 10,  1,  9,  3,  7,  6,  4]), tensor([5, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR6HXBZUSnw-"
      },
      "source": [
        "train_t_u = t_u[train_indices]\n",
        "train_t_c = t_c[train_indices]\n",
        "\n",
        "val_t_u = t_u[val_indices]\n",
        "val_t_c = t_c[val_indices]\n",
        "\n",
        "train_t_un = 0.1 * train_t_u\n",
        "val_t_un = 0.1 * val_t_u"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E3dOvj1TxaC"
      },
      "source": [
        "**A. What parts of the training loop, and so on, need to change to accommodate this redefinition?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGRaJg90VYJJ"
      },
      "source": [
        "\n",
        "\n",
        "*   model 함수를 일차함수가 아닌 2차함수로 바꾸어야 합니다. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owdsqMqESfFD"
      },
      "source": [
        "def model(t_u, w1, w2, b):\n",
        "  return w1*(t_u)*(t_u) + w2 * t_u + b\n",
        "\n",
        "## Mean Squared Error  \n",
        "def loss_fn(t_p, t_c):\n",
        "  squared_diffs = (t_p-t_c)**2\n",
        "  return squared_diffs.mean()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw010DsAU3_E"
      },
      "source": [
        "**B. What parts are agnostic to swapping out the model?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjbzdW4oWZ92"
      },
      "source": [
        "\n",
        "\n",
        "*   loss function과 optimizer 등이 모델 구조에 관계없이 자유롭습니다. \n",
        "* 데이터 구성 역시 영향을 받지 않습니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPjEaKUPU9SG"
      },
      "source": [
        "**C. Is the resulting loss higher or lower after training?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AbmW6bZWrKt"
      },
      "source": [
        "\n",
        "\n",
        "*   loss가 학습에 진행됨에 따라 커집니다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RytbjbZtS2XU"
      },
      "source": [
        "def training_loop(n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
        "  for epoch in range(1, n_epochs+1):\n",
        "    \n",
        "    if params.grad is not None:\n",
        "      params.grad.zero_()  \n",
        "    with torch.set_grad_enabled(True):\n",
        "      train_t_p = model(train_t_u, *params)\n",
        "      train_loss = loss_fn(train_t_p, train_t_c)\n",
        "    with torch.no_grad():\n",
        "      val_t_p = model(val_t_u, *params)\n",
        "      val_loss = loss_fn(val_t_p, val_t_c)\n",
        "      assert val_loss.requires_grad==False\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch<=3 or epoch % 500 == 0:\n",
        "      print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f}, \"f\"Validation loss{val_loss.item():.4f}\")\n",
        "  return params"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUQ8VpJwS3u0",
        "outputId": "e66e9961-0988-482f-b6ba-0213c96eacde",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "params = torch.tensor([-1.0, 1.0, 0.0], requires_grad=True)\n",
        "learning_rate = 1e-2\n",
        "optimizer = optim.SGD([params], lr=learning_rate)\n",
        "\n",
        "training_loop(\n",
        "    n_epochs=3000,\n",
        "    optimizer=optimizer,\n",
        "    params=params,\n",
        "    train_t_u=train_t_un,\n",
        "    val_t_u=val_t_un,\n",
        "    train_t_c=train_t_c,\n",
        "    val_t_c=val_t_c\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Training loss 2075.6345, Validation loss411.8989\n",
            "Epoch 2, Training loss 1389392.2500, Validation loss400968.2500\n",
            "Epoch 3, Training loss 936391744.0000, Validation loss266650976.0000\n",
            "Epoch 500, Training loss nan, Validation lossnan\n",
            "Epoch 1000, Training loss nan, Validation lossnan\n",
            "Epoch 1500, Training loss nan, Validation lossnan\n",
            "Epoch 2000, Training loss nan, Validation lossnan\n",
            "Epoch 2500, Training loss nan, Validation lossnan\n",
            "Epoch 3000, Training loss nan, Validation lossnan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([nan, nan, nan], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bocwNsvlVJyG"
      },
      "source": [
        "**D. Is the actual result better or worse?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJC6EQAhWwTN"
      },
      "source": [
        "\n",
        "\n",
        "*   실제 결과는 더 안 좋습니다. loss function의 backpropagation이 이차함수에 맞춰 구현이 되어있지 않기 때문입니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNdtqCerTXVS"
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}